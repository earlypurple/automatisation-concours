#!/usr/bin/env python3
"""
üéØ SYST√àME ULTRA-AVANC√â DE SURVEILLANCE GRATUITE V3.0 - Orchestrateur
"""
import time
import threading
import schedule
import os
import joblib
import redis
from app import app, api_server
from waitress import serve
import selection_logic
import train_model
from logger import logger

import email_handler
import analytics
import database as db

# --- Gestion du Mod√®le d'IA ---
MODEL_PATH = 'opportunity_model.joblib'
model_lock = threading.Lock()  # Le mod√®le est charg√© ici et inject√© dans les modules qui en ont besoin.
model = None

def load_model():
    """
    Charge le mod√®le d'IA √† partir du fichier.
    Cette fonction est thread-safe.
    """
    global model
    with model_lock:
        if os.path.exists(MODEL_PATH):
            try:
                model = joblib.load(MODEL_PATH)
                selection_logic.model = model  # Injection dans le module de scoring
                logger.info("ü§ñ Mod√®le d'IA charg√© avec succ√®s.")
            except Exception as e:
                logger.error(f"‚ö†Ô∏è Erreur lors du chargement du mod√®le d'IA: {e}")
                model = None
                selection_logic.model = None
        else:
            logger.info("‚ÑπÔ∏è Aucun mod√®le d'IA trouv√©. Le scoring de fallback sera utilis√©.")
            model = None
            selection_logic.model = None


def reload_model():
    """Recharge le mod√®le d'IA pour refl√©ter les changements (ex: r√©-entra√Ænement)."""
    logger.info("üîÑ Rechargement du mod√®le d'IA demand√©...")
    load_model()


def trigger_scraping_job(r):
    """Envoie un job de scraping √† la file d'attente Redis."""
    logger.info("üöÄ Envoi d'un job de scraping √† la file d'attente...")
    r.publish('scraping_jobs', 'start_scraping')


def run_scheduler(r):
    """Runs the scheduled tasks for scraping."""
    # La configuration de l'intervalle est maintenant lue depuis config.json
    # que le scraper utilisera aussi. C'est une simplification pour l'instant.
    schedule.every(60).minutes.do(trigger_scraping_job, r=r)
    logger.info("Planificateur de scraping d√©marr√©. Les jobs seront envoy√©s √† Redis.")
    while True:
        schedule.run_pending()
        time.sleep(1)


def run_training_scheduler(config):
    """Ex√©cute les t√¢ches planifi√©es pour l'entra√Ænement du mod√®le d'IA."""
    training_config = config.get('ai_training', {})
    if not training_config.get('enabled', True):
        logger.info("L'entra√Ænement continu de l'IA est d√©sactiv√© dans la configuration.")
        return

    interval = training_config.get('training_interval_hours', 24)
    if not isinstance(interval, (int, float)) or interval <= 0:
        interval = 24

    logger.info(f"ü§ñ Planificateur d'entra√Ænement de l'IA d√©marr√©. Prochain entra√Ænement dans {interval} heures.")
    schedule.every(interval).hours.do(train_model.train_and_save_model)

    while True:
        schedule.run_pending()
        time.sleep(60)


def run_email_scheduler(config):
    """Runs the scheduled tasks for email checking."""
    email_config = config.get('email_handler', {})
    if not email_config.get('enabled'):
        logger.info("Le gestionnaire d'e-mails est d√©sactiv√© dans la configuration, le planificateur ne d√©marrera pas.")
        return
    interval = email_config.get('check_interval_minutes', 15)
    schedule.every(interval).minutes.do(email_handler.process_pending_confirmations, config=config)

    logger.info("Planificateur d'e-mails d√©marr√©.")
    while True:
        schedule.run_pending()
        time.sleep(1)


if __name__ == "__main__":
    # 0. Charger le mod√®le d'IA au d√©marrage
    load_model()

    # 1. Initialiser le client Redis
    redis_host = os.getenv('REDIS_HOST', 'localhost')
    redis_client = redis.Redis(host=redis_host, port=6379, db=0)

    # 2. Lancer la surveillance initiale
    trigger_scraping_job(redis_client)

    # 3. D√©marrer les planificateurs dans des threads s√©par√©s
    scraping_scheduler_thread = threading.Thread(target=run_scheduler, args=(redis_client,), daemon=True)
    scraping_scheduler_thread.start()

    # Pour l'instant, on suppose que la config est lue depuis le fichier par les modules.
    # Dans une version plus avanc√©e, on pourrait passer la config via Redis ou autre.
    import config_handler
    app_config = config_handler.load_config()

    email_scheduler_thread = threading.Thread(target=run_email_scheduler, args=(app_config,), daemon=True)
    email_scheduler_thread.start()

    training_scheduler_thread = threading.Thread(target=run_training_scheduler, args=(app_config,), daemon=True)
    training_scheduler_thread.start()

    # 4. D√©marrer le serveur d'API
    logger.info("üöÄ D√©marrage du serveur d'API Flask...")
    api_server.start_worker()
    serve(app, host='0.0.0.0', port=8080)
