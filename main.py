#!/usr/bin/env python3
"""
üéØ SYST√àME ULTRA-AVANC√â DE SURVEILLANCE GRATUITE V3.0 - Orchestrateur
"""
import time
import threading
import schedule
import os
import joblib
from scraper import SurveillanceUltraAvancee
from server import APIServer
import selection_logic
import train_model

import email_handler

# --- Gestion du Mod√®le d'IA ---
MODEL_PATH = 'opportunity_model.joblib'
model_lock = threading.Lock()
# Le mod√®le est charg√© ici et inject√© dans les modules qui en ont besoin.
model = None

def load_model():
    """
    Charge le mod√®le d'IA √† partir du fichier.
    Cette fonction est thread-safe.
    """
    global model
    with model_lock:
        if os.path.exists(MODEL_PATH):
            try:
                model = joblib.load(MODEL_PATH)
                selection_logic.model = model  # Injection dans le module de scoring
                print("ü§ñ Mod√®le d'IA charg√© avec succ√®s.")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors du chargement du mod√®le d'IA: {e}")
                model = None
                selection_logic.model = None
        else:
            print("‚ÑπÔ∏è Aucun mod√®le d'IA trouv√©. Le scoring de fallback sera utilis√©.")
            model = None
            selection_logic.model = None

def reload_model():
    """Recharge le mod√®le d'IA pour refl√©ter les changements (ex: r√©-entra√Ænement)."""
    print("üîÑ Rechargement du mod√®le d'IA demand√©...")
    load_model()


def run_scheduler(surv_instance):
    """Runs the scheduled tasks for scraping."""
    scraping_config = surv_instance.config.get('scraping', {})
    interval = scraping_config.get('interval_minutes', 60)
    schedule.every(interval).minutes.do(surv_instance.run_surveillance_complete)
    print("Planificateur de scraping d√©marr√©.")
    while True:
        schedule.run_pending()
        time.sleep(1)

def run_training_scheduler(config):
    """Ex√©cute les t√¢ches planifi√©es pour l'entra√Ænement du mod√®le d'IA."""
    training_config = config.get('ai_training', {})
    if not training_config.get('enabled', True):
        print("L'entra√Ænement continu de l'IA est d√©sactiv√© dans la configuration.")
        return

    # Mettre une valeur par d√©faut au cas o√π la configuration est absente
    interval = training_config.get('training_interval_hours', 24)
    if not isinstance(interval, (int, float)) or interval <= 0:
        interval = 24 # Fallback √† une valeur s√ªre

    print(f"ü§ñ Planificateur d'entra√Ænement de l'IA d√©marr√©. Prochain entra√Ænement dans {interval} heures.")
    # Planifier la premi√®re ex√©cution, puis les suivantes
    schedule.every(interval).hours.do(train_model.train_and_save_model)

    while True:
        schedule.run_pending()
        time.sleep(60) # Pas besoin de v√©rifier chaque seconde

def run_email_scheduler(config):
    """Runs the scheduled tasks for email checking."""
    email_config = config.get('email_handler', {})
    if not email_config.get('enabled'):
        print("Le gestionnaire d'e-mails est d√©sactiv√© dans la configuration, le planificateur ne d√©marrera pas.")
        return
    interval = email_config.get('check_interval_minutes', 15)

    # Pass the entire config to the scheduler job
    schedule.every(interval).minutes.do(email_handler.process_pending_confirmations, config=config)

    print("Planificateur d'e-mails d√©marr√©.")
    while True:
        schedule.run_pending()
        time.sleep(1)

if __name__ == "__main__":
    # 0. Charger le mod√®le d'IA au d√©marrage
    load_model()

    # 1. Initialiser le scraper
    surv = SurveillanceUltraAvancee()

    # 2. Lancer la surveillance initiale
    surv.run_surveillance_complete()

    # 3. D√©marrer les planificateurs dans des threads s√©par√©s
    scraping_scheduler_thread = threading.Thread(target=run_scheduler, args=(surv,), daemon=True)
    scraping_scheduler_thread.start()

    email_scheduler_thread = threading.Thread(target=run_email_scheduler, args=(surv.config,), daemon=True)
    email_scheduler_thread.start()

    # Nouveau: D√©marrer le planificateur d'entra√Ænement de l'IA
    training_scheduler_thread = threading.Thread(target=run_training_scheduler, args=(surv.config,), daemon=True)
    training_scheduler_thread.start()

    # 4. D√©marrer le serveur d'API
    # Le serveur a besoin d'acc√©der aux stats mises √† jour par le scraper
    server = APIServer(
        host=surv.config.get('server', {}).get('host', 'localhost'),
        port=surv.config.get('server', {}).get('port', 8080),
        stats_provider=lambda: surv.stats
    )
    server.run()
